<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Do not use averages with Likert scale data</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is a short overview of why averages don’t work well for evaluating Likert scale or other ordinal-scale data, and what to do instead, with examples using R.">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Do not use averages with Likert scale data" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://bookdown.org/Rmadillo/likert/" />
  <meta property="og:image" content="https://bookdown.org/Rmadillo/likert/images/likert_cover.jpg" />
  <meta property="og:description" content="This is a short overview of why averages don’t work well for evaluating Likert scale or other ordinal-scale data, and what to do instead, with examples using R." />
  <meta name="github-repo" content="Rmadillo/likert" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Do not use averages with Likert scale data" />
  
  <meta name="twitter:description" content="This is a short overview of why averages don’t work well for evaluating Likert scale or other ordinal-scale data, and what to do instead, with examples using R." />
  <meta name="twitter:image" content="https://bookdown.org/Rmadillo/likert/images/likert_cover.jpg" />

<meta name="author" content="Dwight Barry">


<meta name="date" content="2017-01-04">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="how-many-respondents-are-enough.html">
<link rel="next" href="a-final-word.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Do not use means with Likert scales</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#r-packgaes"><i class="fa fa-check"></i><b>0.1</b> R packgaes</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#data"><i class="fa fa-check"></i><b>0.2</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1</b> Summary</a></li>
<li class="chapter" data-level="2" data-path="why-not-a-simple-example.html"><a href="why-not-a-simple-example.html"><i class="fa fa-check"></i><b>2</b> <em>Why not?</em> A simple example</a></li>
<li class="chapter" data-level="3" data-path="always-visualize.html"><a href="always-visualize.html"><i class="fa fa-check"></i><b>3</b> <em>Always</em> visualize</a><ul>
<li class="chapter" data-level="3.1" data-path="always-visualize.html"><a href="always-visualize.html#histograms"><i class="fa fa-check"></i><b>3.1</b> Histograms</a></li>
<li class="chapter" data-level="3.2" data-path="always-visualize.html"><a href="always-visualize.html#likert-charts"><i class="fa fa-check"></i><b>3.2</b> Likert charts</a></li>
<li class="chapter" data-level="3.3" data-path="always-visualize.html"><a href="always-visualize.html#other-ordinal-scale-visualizations"><i class="fa fa-check"></i><b>3.3</b> Other ordinal-scale visualizations</a><ul>
<li class="chapter" data-level="3.3.1" data-path="always-visualize.html"><a href="always-visualize.html#heatmap"><i class="fa fa-check"></i><b>3.3.1</b> Heatmap</a></li>
<li class="chapter" data-level="3.3.2" data-path="always-visualize.html"><a href="always-visualize.html#likert-chart-with-response-count-histograms"><i class="fa fa-check"></i><b>3.3.2</b> Likert chart with response count histograms</a></li>
<li class="chapter" data-level="3.3.3" data-path="always-visualize.html"><a href="always-visualize.html#likert-chart-with-subgroups"><i class="fa fa-check"></i><b>3.3.3</b> Likert chart with subgroups</a></li>
<li class="chapter" data-level="3.3.4" data-path="always-visualize.html"><a href="always-visualize.html#density-histograms"><i class="fa fa-check"></i><b>3.3.4</b> Density histograms</a></li>
<li class="chapter" data-level="3.3.5" data-path="always-visualize.html"><a href="always-visualize.html#scatterplots-ordinal-correlation"><i class="fa fa-check"></i><b>3.3.5</b> Scatterplots &amp; ordinal correlation</a></li>
<li class="chapter" data-level="3.3.6" data-path="always-visualize.html"><a href="always-visualize.html#monitoring-ordinal-data"><i class="fa fa-check"></i><b>3.3.6</b> Monitoring ordinal data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="neutral-scores-matter.html"><a href="neutral-scores-matter.html"><i class="fa fa-check"></i><b>4</b> <em>Neutral</em> scores matter</a></li>
<li class="chapter" data-level="5" data-path="how-many-respondents-are-enough.html"><a href="how-many-respondents-are-enough.html"><i class="fa fa-check"></i><b>5</b> How many respondents are enough?</a></li>
<li class="chapter" data-level="6" data-path="is-there-a-significant-difference.html"><a href="is-there-a-significant-difference.html"><i class="fa fa-check"></i><b>6</b> Is there a <em>significant</em> difference?</a><ul>
<li class="chapter" data-level="6.1" data-path="is-there-a-significant-difference.html"><a href="is-there-a-significant-difference.html#permutation-mann-whitney-tests"><i class="fa fa-check"></i><b>6.1</b> Permutation &amp; Mann-Whitney tests</a></li>
<li class="chapter" data-level="6.2" data-path="is-there-a-significant-difference.html"><a href="is-there-a-significant-difference.html#effect-sizes-cis"><i class="fa fa-check"></i><b>6.2</b> Effect sizes &amp; CIs</a></li>
<li class="chapter" data-level="6.3" data-path="is-there-a-significant-difference.html"><a href="is-there-a-significant-difference.html#chi2-test"><i class="fa fa-check"></i><b>6.3</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="6.4" data-path="is-there-a-significant-difference.html"><a href="is-there-a-significant-difference.html#Advanced"><i class="fa fa-check"></i><b>6.4</b> Multinomial regression</a></li>
<li class="chapter" data-level="6.5" data-path="is-there-a-significant-difference.html"><a href="is-there-a-significant-difference.html#proportional-odds-regression"><i class="fa fa-check"></i><b>6.5</b> Proportional-odds regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="a-final-word.html"><a href="a-final-word.html"><i class="fa fa-check"></i><b>7</b> A final word</a></li>
<li class="chapter" data-level="" data-path="appendix-measurement-levels-summary-statistics.html"><a href="appendix-measurement-levels-summary-statistics.html"><i class="fa fa-check"></i>Appendix: Measurement Levels &amp; Summary Statistics</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Do not use averages with Likert scale data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="is-there-a-significant-difference" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Is there a <em>significant</em> difference?</h1>
<p>Many decision-makers want to know if a result is “significantly different” from, say, the same response from a previous time period, or between a couple of subgroups in the same response, typically asking for identification of questions in which <em>p</em> &lt; 0.05 using a <em>t</em>-test. Unfortunately, this is mostly useless, for two reasons.</p>
<p>First, acting as if Likert or other ordinal scales are continuous level data leads to many problems of interpretation (see the <em>Appendix</em> for a summary table of measurement scales and appropriate statistics). There has been controversy over this distinction for many decades; however, a great way to understand the conceptual problem is to realize that the mean of <em>Agree</em> and <em>Strongly Agree</em> is <strong>not</strong> <em>Agree-And-A-Half</em>—it just makes no sense.</p>
<p>A subsequent argument might be that, no, it’s not conceptually accurate, but it provides a sense for directional changes. However, such results still run into problems of interpretation: if you go from 4.17 to 4.33, have you gone from <em>Agree.17</em> to <em>Agree.33</em>? What does such an “improvement” mean, in practical terms? All you can accurately say is that both values are most consistent with an <em>Agree</em> opinion.</p>
<p>Specifically in the medicine/healthcare context, <a href="https://www.ncbi.nlm.nih.gov/pubmed/8883724">Kuzon et al.</a> state that the use of parametric statistics on ordinal data (such calculating a mean or using a <em>t</em>-test) is the first of “The seven deadly sins of statistical analysis”. Don’t “sin” and you don’t have to worry about whether your results are illegitimate.</p>
<p>There are a few ways around this problem: 1) use medians or other quantiles and test for differences in those statistics (these differences are best assessed via bootstrap or permutation testing), 2) test whether the distribution has shifted (Mann-Whitney-Wilcoxon or <span class="math inline">\(\chi^2\)</span> tests), or 3) use more advanced techniques such as multinomial or proportional-odds regression (see the <a href="is-there-a-significant-difference.html#Advanced"><em>Advanced</em></a> section, below). These options are the more statistically-correct ways to do it (as opposed a <em>t</em>-test).</p>
<p>However, even if you are using the correct tests, the <a href="https://en.wikipedia.org/wiki/Multiple_comparisons_problem">multiple-testing problem</a> remains if you are using traditional/frequentist inference. Make sure you <a href="http://xkcd.com/882/">consider the possibility of false-positives</a> in any interpretation of mass-testing results, or use <a href="http://labstats.net/articles/overview.html">other inferential approaches</a> such as Bayesian or Information-Theoretic instead (the <a href="is-there-a-significant-difference.html#Advanced"><em>Advanced</em></a> section, below, uses an <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">AIC-based Information-Theoretic approach</a> for the model results compared against a no-difference model).</p>
<div id="permutation-mann-whitney-tests" class="section level2">
<h2><span class="header-section-number">6.1</span> Permutation &amp; Mann-Whitney tests</h2>
<p>So, using the simple example from Chapter 1, we might want to know whether the median is statistically different between year 1 (Median = 4) and year 2 (Median = 5). Running a <a href="https://en.wikipedia.org/wiki/Resampling_(statistics)#Permutation_tests">permutation test</a> gives us the following results:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Subset to years 1 and 2</span>
ex_1_long_y12 =<span class="st"> </span><span class="kw">filter</span>(ex_1_long, variable ==<span class="st"> &quot;year1&quot;</span> |<span class="st"> </span>variable ==<span class="st"> &quot;year2&quot;</span>)

<span class="co"># Permutation test</span>
<span class="kw">oneway_test</span>(value ~<span class="st"> </span>variable, <span class="dt">data =</span> ex_1_long_y12, <span class="dt">distribution =</span> <span class="st">&quot;exact&quot;</span>)</code></pre></div>
<pre><code>&gt;  
&gt;   Exact Two-Sample Fisher-Pitman Permutation Test
&gt;  
&gt;  data:  value by variable (year1, year2)
&gt;  Z = -0.33333, p-value = 1
&gt;  alternative hypothesis: true mu is not equal to 0</code></pre>
<p>While our effect size is “1”—more accurately, <em>Agree</em> to <em>Strongly Agree</em>—the <em>p</em>-value of the test is very large (basically 1), so we cannot say that this difference is “statistically significant”.</p>
<p>We could also ask, “has the distribution shifted?”, which would involve using the <a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test">Mann-Whitney-Wilcoxon test</a>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(value ~<span class="st"> </span>variable, <span class="dt">data =</span> ex_1_long_y12) </code></pre></div>
<pre><code>&gt;  
&gt;   Wilcoxon rank sum test with continuity correction
&gt;  
&gt;  data:  value by variable
&gt;  W = 11.5, p-value = 0.285
&gt;  alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>The <em>p</em>-value is non-significant, so the difference between year 1 and year 2 can’t be assumed to be a statistically significant change.</p>
<p>Looking at the raw data or graphs seen earlier, a decision-maker might be justified in wanting to act, but the analysis suggests that the difference is not statistically significant.</p>
<p>This leads us to the second problem with using <em>p</em>-values for determining whether a statistically-significant difference has occurred: sample size.</p>
<p><em>p</em>-values are directly dependent on sample size. If your sample is large enough, you are guaranteed to have a small <em>p</em>-value. If your sample is small, whether or not you get a significant <em>p</em>-value depends on the scale of difference between the groups, i.e., the effect size.</p>
<p>For example, consider the following examples evaluating the number of people who answer <em>Agree</em> or <em>Strongly Agree</em> (the “favorable” score group) to a question:</p>
<table>
<thead>
<tr class="header">
<th>Example</th>
<th align="right">Favorable</th>
<th align="right">Total Answers</th>
<th align="center">Effect size</th>
<th align="center"><em>p</em>-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td align="right">15</td>
<td align="right">20</td>
<td align="center">75%</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td>2</td>
<td align="right">114</td>
<td align="right">200</td>
<td align="center">57%</td>
<td align="center">0.04</td>
</tr>
<tr class="odd">
<td>3</td>
<td align="right">1,046</td>
<td align="right">2,000</td>
<td align="center">52%</td>
<td align="center">0.04</td>
</tr>
<tr class="even">
<td>4</td>
<td align="right">1,001,450</td>
<td align="right">2,000,000</td>
<td align="center">50%</td>
<td align="center">0.04</td>
</tr>
</tbody>
</table>
<p>With 15 of 20 people selecting a favorable value on the Likert scale, we have an effect size of 75%, which is certainly an effect worth taking seriously. That value is also a statistically significant difference (<em>p</em> &lt; 0.05), which supports the idea that the majority has a favorable opinion. With a couple of thousand responses (example 3), we again have a statistically significant difference, but the effect size is now only 52%, close enough to even-preference as to be <em>practically</em> the same. In medical terms, we might think of this as statistically significant but clinically irrelevant.</p>
</div>
<div id="effect-sizes-cis" class="section level2">
<h2><span class="header-section-number">6.2</span> Effect sizes &amp; CIs</h2>
<p>For these reasons—<a href="http://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108">and many others outside the scope of these guidelines</a>—statisticians are moving away from the use of <em>p</em>-values. In frequentist statistics, these are being replaced by the use of effect sizes and confidence intervals (CIs); these provide information on both on the precision of the estimated difference, as well as whether the difference can be considered statistically distinct. If the CI includes 0, the difference is not-significant. Regardless of the location of 0, the width of the CI tells you how precise your estimate is.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">median_diff =<span class="st"> </span><span class="kw">two.boot</span>(year1, year2, median, <span class="dt">R=</span><span class="dv">1000</span>)
<span class="kw">cat</span>(<span class="kw">paste0</span>(<span class="st">&quot;Difference in medians is &quot;</span>, <span class="kw">abs</span>(median_diff$t0), <span class="st">&quot;.&quot;</span>))</code></pre></div>
<pre><code>&gt;  Difference in medians is 1.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boot.ci</span>(median_diff, <span class="dt">type =</span> <span class="st">&quot;perc&quot;</span>) </code></pre></div>
<pre><code>&gt;  BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
&gt;  Based on 1000 bootstrap replicates
&gt;  
&gt;  CALL : 
&gt;  boot.ci(boot.out = median_diff, type = &quot;perc&quot;)
&gt;  
&gt;  Intervals : 
&gt;  Level     Percentile     
&gt;  95%   (-1,  1 )  
&gt;  Calculations and Intervals on Original Scale</code></pre>
<p>Here, we see that the effect size is a difference in medians of 1, but the confidence interval on that effect size goes from -1 to +1, i.e. is consistent with any score difference between <em>Neutral</em> and <em>Strongly Agree</em>. Since that CI includes 0, we can’t say that the change from median of <em>Agree</em> to a median of <em>Strongly Agree</em> is statistically different, though again, sample size matters—one would probably like to try to intervene based on the one respondent who dropped down to 2 (<em>Disagree</em>) anyway.</p>
</div>
<div id="chi2-test" class="section level2">
<h2><span class="header-section-number">6.3</span> <span class="math inline">\(\chi^2\)</span> test</h2>
<p>While Mann-Whitney-Wilcoxon (sometimes known as the Mann-Whitney <em>U</em>-test) is the test most often used with differences between ordinal distributions, there are other options that can tell you whether a measured difference between groups is statistical different.</p>
<p>The old stand-by in this case is the <span class="math inline">\(\chi^2\)</span> test, which is often best visualized with a mosaic plot (Figure 11).</p>
<p><em>Mosaic plot between Employee Type and responses to the ‘My team works well together’ question.</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Figure 11</span>
<span class="kw">mosaicplot</span>(both2_tab, <span class="dt">shade =</span> T, <span class="dt">main=</span><span class="st">&quot;&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Employee Type&quot;</span>, 
  <span class="dt">ylab=</span><span class="st">&quot;My team works well together&quot;</span>)</code></pre></div>
<p><img src="likert_files/figure-html/chisq-1.png" width="432" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Chi-square test</span>
<span class="kw">chisq.test</span>(both2_tab)</code></pre></div>
<pre><code>&gt;  
&gt;   Pearson&#39;s Chi-squared test
&gt;  
&gt;  data:  both2_tab
&gt;  X-squared = 52.809, df = 4, p-value = 9.344e-11</code></pre>
</div>
<div id="Advanced" class="section level2">
<h2><span class="header-section-number">6.4</span> Multinomial regression</h2>
<p>The multinomial regression model is a more powerful (and more modern) version of the <span class="math inline">\(\chi^2\)</span> test. Here, we’re using an AIC-based information-theoretic approach to determine whether the data as we see it is as likely a model as a model that suggests no difference between MD and RN responses. The probabilities can be plotted with a line chart for easy comparison.</p>
<p><em>Multinomial regression between Employee Type and responses to the ‘My team works well together’ question, with information-theoretic table for multi-model inference.</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Multinomial regression</span>
multnom_both =<span class="st"> </span><span class="kw">multinom</span>(Teamwork ~<span class="st"> </span>EmployeeType, <span class="dt">data =</span> both3, <span class="dt">trace =</span> <span class="ot">FALSE</span>)
multnom_both_1 =<span class="st"> </span><span class="kw">multinom</span>(Teamwork ~<span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> both3, <span class="dt">trace =</span> <span class="ot">FALSE</span>)

<span class="co"># New data for prediction</span>
df_both =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">EmployeeType =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;MD&quot;</span>, <span class="st">&quot;RN&quot;</span>), <span class="dt">each =</span> <span class="dv">5</span>),  
  <span class="dt">Teamwork =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">5</span>), <span class="dv">2</span>))

<span class="co"># Get probabilities</span>
multnom_both_probs =<span class="st"> </span><span class="kw">cbind</span>(df_both, <span class="kw">predict</span>(multnom_both, 
  <span class="dt">newdata =</span> df_both, <span class="dt">type =</span> <span class="st">&quot;probs&quot;</span>, <span class="dt">se =</span> <span class="ot">TRUE</span>))

<span class="co"># Clean up, ugh</span>
multnom_both_probs =<span class="st"> </span>multnom_both_probs[,-<span class="dv">2</span>]
multnom_both_probs =<span class="st"> </span><span class="kw">unique</span>(multnom_both_probs)

<span class="co"># Make data frame for ggplot, probably should figure out tidyr</span>
multnom_both_probs_df =<span class="st"> </span>reshape2::<span class="kw">melt</span>(multnom_both_probs, 
  <span class="dt">id.vars =</span> <span class="st">&quot;EmployeeType&quot;</span>, <span class="dt">variable.name =</span> <span class="st">&quot;Teamwork&quot;</span>, 
  <span class="dt">value.name =</span> <span class="st">&quot;probability&quot;</span>)

<span class="co"># Figure 12</span>
<span class="kw">ggplot</span>(multnom_both_probs_df, <span class="kw">aes</span>(<span class="dt">x =</span> Teamwork, <span class="dt">y =</span> probability, 
    <span class="dt">color =</span> EmployeeType, <span class="dt">group =</span> EmployeeType)) +
<span class="st">  </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;My team works well together&quot;</span>)</code></pre></div>
<p><img src="likert_files/figure-html/multnom-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>There appears to be an effect based on Employee Type; the AIC weight for that model is practically 1, making it clearly the best model of the model set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># AICc table</span>
mod_set =<span class="st"> </span><span class="kw">list</span>()
    mod_set[[<span class="dv">1</span>]] =<span class="st"> </span>multnom_both
    mod_set[[<span class="dv">2</span>]] =<span class="st"> </span>multnom_both_1

<span class="kw">kable</span>(<span class="kw">aictab</span>(mod_set, <span class="dt">modnames =</span> <span class="kw">c</span>(<span class="st">&quot;Employee Type&quot;</span>, <span class="st">&quot;Null Model&quot;</span>)))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modnames</th>
<th align="right">K</th>
<th align="right">AICc</th>
<th align="right">Delta_AICc</th>
<th align="right">ModelLik</th>
<th align="right">AICcWt</th>
<th align="right">LL</th>
<th align="right">Cum.Wt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Employee Type</td>
<td align="right">8</td>
<td align="right">472.0249</td>
<td align="right">0.00000</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">-227.5680</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Null Model</td>
<td align="right">4</td>
<td align="right">522.0647</td>
<td align="right">50.03976</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">-256.9118</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
</div>
<div id="proportional-odds-regression" class="section level2">
<h2><span class="header-section-number">6.5</span> Proportional-odds regression</h2>
<p>If you can meet the assumptions, the proportional-odds regression is more powerful than the multinomial model, as it can take into account the ordered nature of the ordinal scale.</p>
<p>Again, we use the information-theoretic approach to determine whether there is an effect based on Employee Type, again plotted with a line chart for easy comparison. And again the AICc results suggest an effect is present. The probabilities are slightly different from the multinomial model, but may be more accurate since we are now accounting for the ordered nature of the response values.</p>
<p><em>Proportional odds regression between Employee Type and responses to the ‘My team works well together’ question, with information-theoretic table for multi-model inference.</em></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Proportional odds regression with polr</span>
polr_both =<span class="st"> </span><span class="kw">polr</span>(Teamwork ~<span class="st"> </span>EmployeeType, <span class="dt">data =</span> Teamwork_tab_long, 
  <span class="dt">weight =</span> Count)

<span class="co"># New data for prediction, same as multinom</span>
df_both =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">EmployeeType =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;MD&quot;</span>, <span class="st">&quot;RN&quot;</span>), <span class="dt">each =</span> <span class="dv">5</span>),  
  <span class="dt">Teamwork =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">5</span>), <span class="dv">2</span>))

<span class="co"># Get probabilities</span>
polr_both_probs =<span class="st"> </span><span class="kw">cbind</span>(df_both, <span class="kw">predict</span>(polr_both, <span class="dt">newdata =</span> df_both, 
  <span class="dt">type =</span> <span class="st">&quot;probs&quot;</span>, <span class="dt">se =</span> <span class="ot">TRUE</span>))

<span class="co"># Clean up, ugh</span>
polr_both_probs =<span class="st"> </span>polr_both_probs[,-<span class="dv">2</span>]
polr_both_probs =<span class="st"> </span><span class="kw">unique</span>(polr_both_probs)

<span class="co"># Make data frame for ggplot, probably should figure out tidyr</span>
polr_both_probs_df =<span class="st"> </span>reshape2::<span class="kw">melt</span>(polr_both_probs, <span class="dt">id.vars =</span> <span class="st">&quot;EmployeeType&quot;</span>, 
  <span class="dt">variable.name =</span> <span class="st">&quot;Teamwork&quot;</span>, <span class="dt">value.name =</span> <span class="st">&quot;probability&quot;</span>)

<span class="co"># Figure 13</span>
<span class="kw">ggplot</span>(polr_both_probs_df, <span class="kw">aes</span>(<span class="dt">x =</span> Teamwork, <span class="dt">y =</span> probability, 
    <span class="dt">color =</span> EmployeeType, <span class="dt">group =</span> EmployeeType)) +
<span class="st">  </span><span class="kw">geom_line</span>() +<span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;My team works well together&quot;</span>)</code></pre></div>
<p><img src="likert_files/figure-html/prop_odds-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># I need to better understand diffs between polr and clm</span>
<span class="co"># because polr objects don&#39;t play well with the AICcmodavg package</span>
<span class="co"># Coefs/thresholds are exactly the same, though</span>
fm1 =<span class="st"> </span><span class="kw">clm</span>(Teamwork ~<span class="st"> </span>EmployeeType, <span class="dt">data=</span>tab_df)
<span class="co"># Null model</span>
fm2 =<span class="st"> </span><span class="kw">clm</span>(Teamwork ~<span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>tab_df)

<span class="co"># AICc table</span>
mod_set =<span class="st"> </span><span class="kw">list</span>()
    mod_set[[<span class="dv">1</span>]] =<span class="st"> </span>fm1
    mod_set[[<span class="dv">2</span>]] =<span class="st"> </span>fm2

<span class="kw">kable</span>(<span class="kw">aictab</span>(mod_set, <span class="dt">modnames =</span> <span class="kw">c</span>(<span class="st">&quot;Employee Type&quot;</span>, <span class="st">&quot;Null Model&quot;</span>)))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modnames</th>
<th align="right">K</th>
<th align="right">AICc</th>
<th align="right">Delta_AICc</th>
<th align="right">ModelLik</th>
<th align="right">AICcWt</th>
<th align="right">LL</th>
<th align="right">Cum.Wt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Employee Type</td>
<td align="right">5</td>
<td align="right">485.9008</td>
<td align="right">0.00000</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">-237.7686</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Null Model</td>
<td align="right">4</td>
<td align="right">522.0647</td>
<td align="right">36.16387</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">-256.9118</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>We can test the assumption of proportional odds with the <code>anova</code> function. There’s no evidence of a difference, suggesting that the assumption is met.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fm3 =<span class="st"> </span><span class="kw">clm</span>(Teamwork ~<span class="st"> </span>EmployeeType, <span class="dt">data=</span>tab_df, <span class="dt">threshold=</span><span class="st">&quot;equidistant&quot;</span>)
<span class="kw">anova</span>(fm1, fm3)</code></pre></div>
<pre><code>&gt;  Likelihood ratio tests of cumulative link models:
&gt;   
&gt;      formula:                link: threshold: 
&gt;  fm3 Teamwork ~ EmployeeType logit equidistant
&gt;  fm1 Teamwork ~ EmployeeType logit flexible   
&gt;  
&gt;      no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)
&gt;  fm3      3 485.94 -239.97                      
&gt;  fm1      5 485.54 -237.77   4.407  2     0.1104</code></pre>
<p>If the concepts or ideas in this section are confusing, it’s probably worth consulting a statistician for help evaluating your data with these tools.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="how-many-respondents-are-enough.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="a-final-word.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/Rmadillo/likert/edit/master/05-stats.Rmd",
"text": "Edit"
},
"download": ["likert.pdf", "likert.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
